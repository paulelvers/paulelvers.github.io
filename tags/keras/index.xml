<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>keras on paul elvers</title>
    <link>http://paulelvers.com/tags/keras/</link>
    <description>Recent content in keras on paul elvers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© Paul Elvers 2020</copyright>
    <lastBuildDate>Fri, 15 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="http://paulelvers.com/tags/keras/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Multimodal Models</title>
      <link>http://paulelvers.com/posts/multimodal/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://paulelvers.com/posts/multimodal/</guid>
      <description>I still experience a moment of excitement, whenever I start on a new ml project and look at my prediction results for the first time, not sure whether this will be a good model or just garbage. I am not talking about metrics, but just about the actual prediction outputs. There is this thing that so many people working with algorithms may now take for granted, that actually sometimes touches me in this particular moment, when the predictions do &amp;lsquo;make sense&amp;rsquo;: A machine actually learned to produce something meaningful.</description>
    </item>
    
  </channel>
</rss>
